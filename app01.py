import streamlit as st
import requests
from bs4 import BeautifulSoup
from keybert import KeyBERT
import pandas as pd
import time
import re
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import numpy as np
from collections import Counter
import networkx as nx
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import schedule
import threading
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
import io
import os
import platform
import glob

st.set_page_config(page_title="ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ ë‰´ìŠ¤ ìš”ì•½", layout="wide")
st.title("ğŸ“° ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ ë‰´ìŠ¤ ë¶„ì„ ë³´ê³ ì„œ")

# ìºì‹œ í´ë¦¬ì–´ ë²„íŠ¼ (ì‚¬ì´ë“œë°”ì— ì¶”ê°€)
with st.sidebar:
    st.subheader("ğŸ”§ ì‹œìŠ¤í…œ ê´€ë¦¬")
    if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨", help="ìºì‹œëœ ë°ì´í„°ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤"):
        st.cache_data.clear()
        st.success("âœ… ë°ì´í„°ê°€ ìƒˆë¡œê³ ì¹¨ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.rerun()

kw_model = KeyBERT()

# ê¸°ì¡´ CSV íŒŒì¼ ë¡œë“œ
@st.cache_data
def load_existing_data():
    try:
        df = pd.read_csv('digital_healthcare_news.csv')
        # ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ NaNì¸ ê²½ìš° í˜„ì¬ ë‚ ì§œë¡œ ì±„ìš°ê¸°
        if 'date' not in df.columns:
            df['date'] = datetime.now().strftime('%Y-%m-%d')
        else:
            df['date'] = df['date'].fillna(datetime.now().strftime('%Y-%m-%d'))
        return df
    except (FileNotFoundError, pd.errors.EmptyDataError):
        return pd.DataFrame(columns=['title', 'link', 'summary', 'keywords', 'date'])

# ê¸°ì‚¬ ê²€ìƒ‰
def get_yna_article_links(keyword, pages=1):
    articles = []
    for page in range(1, pages + 1):
        url = f"https://www.yna.co.kr/search/index?query={keyword}&page={page}"
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")
        items = soup.select(".cts_atclst > ul > li")
        for item in items:
            title_tag = item.select_one("a.tit")
            if not title_tag:
                continue
            link = title_tag["href"]
            title = title_tag.get_text(strip=True)
            articles.append({"title": title, "link": link})
        time.sleep(1)
    return articles

# ê¸°ì‚¬ ë³¸ë¬¸ ì¶”ì¶œ
def extract_yna_article_text(url):
    try:
        res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=5)
        soup = BeautifulSoup(res.text, "html.parser")
        body_div = soup.find("div", class_="story-news article")
        text = body_div.get_text(separator=" ", strip=True) if body_div else ''
        return text
    except:
        return ''

# ìš”ì•½
def summarize_text(text, ratio=0.3):
    try:
        if not text or len(text.strip()) < 100:
            return text
        
        # ë¬¸ì¥ ë¶„ë¦¬
        sentences = re.split(r'[.!?]\s+', text)
        sentences = [s.strip() for s in sentences if len(s.strip()) > 20]
        
        if not sentences:
            return text
        
        # ìš”ì•½í•  ë¬¸ì¥ ìˆ˜ ê³„ì‚°
        num_sentences = max(1, int(len(sentences) * ratio))
        
        # ì•ë¶€ë¶„ ë¬¸ì¥ë“¤ì„ ìš”ì•½ìœ¼ë¡œ ì‚¬ìš©
        summary_sentences = sentences[:num_sentences]
        return '. '.join(summary_sentences) + '.'
    except:
        return text[:200] + '...' if len(text) > 200 else text

# í‚¤ì›Œë“œ
def extract_keywords(text, top_n=5):
    try:
        keywords = kw_model.extract_keywords(text, top_n=top_n, stop_words="english")
        return [kw[0] for kw in keywords]
    except:
        return []

# TextRank ìš”ì•½ (ê·¸ë˜í”„ ê¸°ë°˜)
def textrank_summarize(text, ratio=0.4):
    try:
        if not text or len(text.strip()) < 50:
            return text
        
        sentences = re.split(r'[.!?]\s+', text)
        sentences = [s.strip() for s in sentences if len(s.strip()) > 10]
        
        if len(sentences) < 2:
            return sentences[0] if sentences else text
        
        # TF-IDF ë²¡í„°í™” (í•œê¸€ ì²˜ë¦¬ ê°œì„ )
        vectorizer = TfidfVectorizer(
            stop_words=None,
            max_features=1000,
            ngram_range=(1, 2)
        )
        
        try:
            tfidf_matrix = vectorizer.fit_transform(sentences)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarity_matrix = cosine_similarity(tfidf_matrix)
            
            # ê·¸ë˜í”„ ìƒì„± ë° PageRank ì ìš©
            nx_graph = nx.from_numpy_array(similarity_matrix)
            scores = nx.pagerank(nx_graph, max_iter=100)
            
            # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ ì„ íƒ (ìƒìœ„ ì ìˆ˜ ë¬¸ì¥ë“¤)
            num_sentences = max(1, min(len(sentences), int(len(sentences) * ratio)))
            ranked_sentences = sorted(((scores[i], i, s) for i, s in enumerate(sentences)), reverse=True)
            
            # ì›ë˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•´ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ìš”ì•½ ìƒì„±
            selected_indices = sorted([idx for _, idx, _ in ranked_sentences[:num_sentences]])
            summary_sentences = [sentences[i] for i in selected_indices]
            
            return '. '.join(summary_sentences) + '.'
        except:
            # TF-IDF ì‹¤íŒ¨ì‹œ ë‹¨ìˆœ ì•ë¶€ë¶„ ì„ íƒ
            num_sentences = max(1, int(len(sentences) * ratio))
            return '. '.join(sentences[:num_sentences]) + '.'
            
    except:
        return text[:150] + '...' if len(text) > 150 else text

# KoBART ìŠ¤íƒ€ì¼ ìš”ì•½ (í‚¤ì›Œë“œ ì¤‘ì‹¬)
def kobart_style_summarize(text, ratio=0.2):
    try:
        if not text or len(text.strip()) < 50:
            return text
        
        sentences = re.split(r'[.!?]\s+', text)
        sentences = [s.strip() for s in sentences if len(s.strip()) > 10]
        
        if not sentences:
            return text
        
        # ë” ì ê·¹ì ì¸ í‚¤ì›Œë“œ ê¸°ë°˜ ìš”ì•½
        try:
            keywords = extract_keywords(text, top_n=15)
        except:
            keywords = []
        
        # ë¬¸ì¥ë³„ ì ìˆ˜ ê³„ì‚°
        scored_sentences = []
        
        for i, sentence in enumerate(sentences):
            # 1. í‚¤ì›Œë“œ ì ìˆ˜ (ë” ë†’ì€ ê°€ì¤‘ì¹˜)
            keyword_score = 0
            for keyword in keywords:
                if keyword.lower() in sentence.lower():
                    keyword_score += 2  # í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì¦ê°€
            
            # 2. ìœ„ì¹˜ ì ìˆ˜ (ì²« ë¬¸ì¥ê³¼ ë§ˆì§€ë§‰ ë¬¸ì¥ ì¤‘ìš”)
            if i == 0:
                position_score = 3  # ì²« ë¬¸ì¥ ë†’ì€ ì ìˆ˜
            elif i == len(sentences) - 1:
                position_score = 2  # ë§ˆì§€ë§‰ ë¬¸ì¥
            else:
                position_score = 1.0 / (i + 1)
            
            # 3. ë¬¸ì¥ ê¸¸ì´ ì ìˆ˜ (ì ë‹¹í•œ ê¸¸ì´ ì„ í˜¸)
            length_score = min(len(sentence) / 100, 1.5)
            
            # 4. ìˆ«ìë‚˜ íŠ¹ìˆ˜ ì •ë³´ í¬í•¨ ì ìˆ˜
            info_score = 0
            if re.search(r'\d+', sentence):  # ìˆ«ì í¬í•¨
                info_score += 0.5
            if any(word in sentence.lower() for word in ['ë°œí‘œ', 'ì—°êµ¬', 'ì¡°ì‚¬', 'ê²°ê³¼', 'íš¨ê³¼']):
                info_score += 0.5
            
            total_score = keyword_score * 2 + position_score + length_score + info_score
            scored_sentences.append((total_score, i, sentence))
        
        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ì„ íƒ
        scored_sentences.sort(reverse=True)
        num_sentences = max(1, min(len(sentences), int(len(sentences) * ratio)))
        
        # ì„ íƒëœ ë¬¸ì¥ë“¤ì„ ì›ë˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬
        selected_sentences = sorted(scored_sentences[:num_sentences], key=lambda x: x[1])
        summary_sentences = [s for _, _, s in selected_sentences]
        
        result = '. '.join(summary_sentences) + '.'
        
        # ë„ˆë¬´ ì§§ìœ¼ë©´ ì¶”ê°€ ë¬¸ì¥ í¬í•¨
        if len(result) < 50 and len(scored_sentences) > num_sentences:
            additional_sentence = scored_sentences[num_sentences][2]
            result += ' ' + additional_sentence + '.'
        
        return result
        
    except:
        return text[:100] + '...' if len(text) > 100 else text

# í•œê¸€ í°íŠ¸ ê²½ë¡œ ì°¾ê¸° (ê°•ë ¥ ë²„ì „)
def get_korean_font_path():
    
    system = platform.system()
    
    # Windows í°íŠ¸ ê²½ë¡œë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)
    if system == "Windows":
        # 1. ê¸°ë³¸ Windows í°íŠ¸ë“¤
        font_paths = [
            "C:/Windows/Fonts/malgun.ttf",      # ë§‘ì€ ê³ ë”•
            "C:/Windows/Fonts/malgunbd.ttf",    # ë§‘ì€ ê³ ë”• Bold
            "C:/Windows/Fonts/gulim.ttc",       # êµ´ë¦¼
            "C:/Windows/Fonts/batang.ttc",      # ë°”íƒ•
            "C:/Windows/Fonts/dotum.ttc",       # ë‹ì›€
            "C:/Windows/Fonts/gungsuh.ttc",     # ê¶ì„œ
        ]
        
        # 2. ë‚˜ëˆ” í°íŠ¸ë“¤
        nanum_fonts = [
            "C:/Windows/Fonts/NanumGothic.ttf",
            "C:/Windows/Fonts/NanumBarunGothic.ttf",
            "C:/Windows/Fonts/NanumSquare.ttf",
        ]
        font_paths.extend(nanum_fonts)
        
        # 3. ì¶”ê°€ í•œê¸€ í°íŠ¸ ê²€ìƒ‰
        additional_patterns = [
            "C:/Windows/Fonts/*gothic*.ttf",
            "C:/Windows/Fonts/*Gothic*.ttf",
            "C:/Windows/Fonts/*í•œê¸€*.ttf",
            "C:/Windows/Fonts/*Korean*.ttf",
        ]
        
        for pattern in additional_patterns:
            font_paths.extend(glob.glob(pattern))
        
    # macOS í°íŠ¸ ê²½ë¡œë“¤
    elif system == "Darwin":
        font_paths = [
            "/System/Library/Fonts/AppleSDGothicNeo.ttc",
            "/Library/Fonts/NanumGothic.ttf",
            "/System/Library/Fonts/Helvetica.ttc"
        ]
    # Linux í°íŠ¸ ê²½ë¡œë“¤
    else:
        font_paths = [
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"
        ]
    
    # ì¡´ì¬í•˜ëŠ” ì²« ë²ˆì§¸ í°íŠ¸ ë°˜í™˜
    for font_path in font_paths:
        if os.path.exists(font_path):
            print(f"í•œê¸€ í°íŠ¸ ë°œê²¬: {font_path}")  # ë””ë²„ê¹…ìš©
            return font_path
    
    # í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ê²½ê³ 
    print("ê²½ê³ : í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    return None

# ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± (í•œê¸€ ì§€ì› ê°•í™”)
def create_wordcloud(text_data):
    try:
        # ëª¨ë“  í‚¤ì›Œë“œ í•©ì¹˜ê¸°
        all_keywords = []
        for keywords_str in text_data:
            if pd.notna(keywords_str):
                keywords = [k.strip() for k in str(keywords_str).split(',')]
                # ë¹ˆ í‚¤ì›Œë“œ ì œê±° ë° í•œê¸€ë§Œ í¬í•¨ëœ í‚¤ì›Œë“œ í•„í„°ë§
                keywords = [k for k in keywords if k and len(k) > 1]
                all_keywords.extend(keywords)
        
        if not all_keywords:
            st.warning("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # í‚¤ì›Œë“œ ë¹ˆë„ ê³„ì‚°
        keyword_freq = Counter(all_keywords)
        
        # ìµœì†Œ ë¹ˆë„ í•„í„°ë§ (ë„ˆë¬´ ì ê²Œ ë‚˜íƒ€ë‚˜ëŠ” í‚¤ì›Œë“œ ì œê±°)
        min_freq = max(1, len(all_keywords) // 50)  # ì „ì²´ì˜ 2% ì´ìƒ
        keyword_freq = {k: v for k, v in keyword_freq.items() if v >= min_freq}
        
        if not keyword_freq:
            st.warning("ì¶©ë¶„í•œ ë¹ˆë„ì˜ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # í•œê¸€ í°íŠ¸ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        font_path = get_korean_font_path()
        
        # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± íŒŒë¼ë¯¸í„°
        wordcloud_params = {
            'width': 1000, 
            'height': 500, 
            'background_color': 'white',
            'max_words': 100,
            'colormap': 'Set3',  # ë” ë‹¤ì–‘í•œ ìƒ‰ìƒ
            'relative_scaling': 0.6,
            'min_font_size': 12,
            'max_font_size': 80,
            'prefer_horizontal': 0.7,  # ê°€ë¡œ í…ìŠ¤íŠ¸ ì„ í˜¸
            'collocations': False,  # ë‹¨ì–´ ì¡°í•© ë°©ì§€
        }
        
        # í•œê¸€ í°íŠ¸ ì„¤ì • (í•„ìˆ˜)
        if font_path:
            wordcloud_params['font_path'] = font_path
            st.success(f"í•œê¸€ í°íŠ¸ ì ìš©ë¨: {os.path.basename(font_path)}")
        else:
            # í°íŠ¸ê°€ ì—†ì–´ë„ ì‹œë„í•´ë³´ê¸°
            st.warning("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
        wordcloud = WordCloud(**wordcloud_params)
        
        # ë¹ˆë„ ë°ì´í„°ë¡œ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
        wordcloud.generate_from_frequencies(keyword_freq)
        
        # ìƒì„± ì„±ê³µ ë©”ì‹œì§€
        st.info(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì™„ë£Œ: {len(keyword_freq)}ê°œ í‚¤ì›Œë“œ ì‚¬ìš©")
        
        return wordcloud
        
    except Exception as e:
        st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        
        # ìƒì„¸ ì˜¤ë¥˜ ì •ë³´ í‘œì‹œ
        import traceback
        with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
            st.code(traceback.format_exc())
        
        return None

# ë§í¬ë¥¼ í•˜ì´í¼ë§í¬ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def make_clickable_links(df):
    """ë°ì´í„°í”„ë ˆì„ì˜ link ì»¬ëŸ¼ì„ í´ë¦­ ê°€ëŠ¥í•œ í•˜ì´í¼ë§í¬ë¡œ ë³€í™˜"""
    df_copy = df.copy()
    if 'link' in df_copy.columns:
        def create_link(url):
            if pd.notna(url) and str(url).strip():
                # URLì´ httpë¡œ ì‹œì‘í•˜ì§€ ì•Šìœ¼ë©´ https ì¶”ê°€
                if not str(url).startswith(('http://', 'https://')):
                    url = 'https://' + str(url)
                return f'<a href="{url}" target="_blank" rel="noopener noreferrer">ğŸ”— ë§í¬</a>'
            return 'ë§í¬ ì—†ìŒ'
        
        df_copy['link'] = df_copy['link'].apply(create_link)
    return df_copy

# ê²€ìƒ‰ í•„í„° í•¨ìˆ˜
def filter_data(df, keyword_filter="", date_filter=None, summary_length_filter=None):
    """ë°ì´í„°í”„ë ˆì„ì„ í•„í„°ë§í•˜ëŠ” í•¨ìˆ˜"""
    filtered_df = df.copy()
    
    # í‚¤ì›Œë“œ í•„í„°
    if keyword_filter:
        mask = (
            filtered_df['title'].str.contains(keyword_filter, case=False, na=False) |
            filtered_df['summary'].str.contains(keyword_filter, case=False, na=False) |
            filtered_df['keywords'].str.contains(keyword_filter, case=False, na=False)
        )
        filtered_df = filtered_df[mask]
    
    # ìš”ì•½ ê¸¸ì´ í•„í„°
    if summary_length_filter:
        min_length, max_length = summary_length_filter
        filtered_df = filtered_df[
            (filtered_df['summary'].str.len() >= min_length) & 
            (filtered_df['summary'].str.len() <= max_length)
        ]
    
    return filtered_df

# ì´ë©”ì¼ ì „ì†¡ í•¨ìˆ˜
def send_email_report(recipient_email, subject, df, sender_email="your_email@gmail.com", sender_password="your_app_password"):
    """ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ì´ë©”ì¼ë¡œ ì „ì†¡í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ì´ë©”ì¼ ë©”ì‹œì§€ ìƒì„±
        msg = MIMEMultipart()
        msg['From'] = sender_email
        msg['To'] = recipient_email
        msg['Subject'] = subject
        
        # HTML í˜•íƒœì˜ ì´ë©”ì¼ ë³¸ë¬¸ ìƒì„±
        html_body = f"""
        <html>
        <head>
            <style>
                table {{ border-collapse: collapse; width: 100%; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
                .header {{ color: #2E86AB; font-size: 24px; margin-bottom: 20px; }}
                .summary {{ background-color: #f9f9f9; padding: 10px; margin: 10px 0; }}
            </style>
        </head>
        <body>
            <div class="header">ğŸ“° ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ ë‰´ìŠ¤ ë¶„ì„ ë³´ê³ ì„œ</div>
            <p><strong>ìƒì„± ì¼ì‹œ:</strong> {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}</p>
            <p><strong>ì´ ê¸°ì‚¬ ìˆ˜:</strong> {len(df)}ê°œ</p>
            
            <h3>ğŸ“Š ë¶„ì„ ê²°ê³¼</h3>
            {df.to_html(escape=False, index=False)}
            
            <div class="summary">
                <h3>ğŸ“ˆ ìš”ì•½ í†µê³„</h3>
                <ul>
                    <li>í‰ê·  ìš”ì•½ ê¸¸ì´: {df['summary'].str.len().mean():.0f}ì</li>
                    <li>ì´ í‚¤ì›Œë“œ ìˆ˜: {sum(len(str(keywords).split(', ')) for keywords in df['keywords'] if pd.notna(keywords))}ê°œ</li>
                </ul>
            </div>
            
            <p><em>ì´ ë³´ê³ ì„œëŠ” ìë™ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.</em></p>
        </body>
        </html>
        """
        
        # HTML ë³¸ë¬¸ ì²¨ë¶€
        msg.attach(MIMEText(html_body, 'html', 'utf-8'))
        
        # CSV íŒŒì¼ ì²¨ë¶€
        csv_data = df.to_csv(index=False, encoding='utf-8-sig')
        csv_attachment = MIMEBase('application', 'octet-stream')
        csv_attachment.set_payload(csv_data.encode('utf-8-sig'))
        encoders.encode_base64(csv_attachment)
        csv_attachment.add_header(
            'Content-Disposition',
            f'attachment; filename="news_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv"'
        )
        msg.attach(csv_attachment)
        
        # Gmail SMTP ì„œë²„ë¥¼ í†µí•´ ì´ë©”ì¼ ì „ì†¡
        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(sender_email, sender_password)
        text = msg.as_string()
        server.sendmail(sender_email, recipient_email, text)
        server.quit()
        
        return True, "ì´ë©”ì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤!"
        
    except Exception as e:
        return False, f"ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {str(e)}"

# ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ê´€ë¦¬
if 'scheduler_running' not in st.session_state:
    st.session_state.scheduler_running = False
if 'scheduler_thread' not in st.session_state:
    st.session_state.scheduler_thread = None

# ìë™ ìŠ¤ì¼€ì¤„ë§ í•¨ìˆ˜
def schedule_daily_news_collection():
    def collect_daily_news():
        try:
            # ë§¤ì¼ ìƒˆë¡œìš´ ë‰´ìŠ¤ ìˆ˜ì§‘
            articles = get_yna_article_links("ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´", pages=1)[:5]
            
            results = []
            for article in articles:
                text = extract_yna_article_text(article["link"])
                summary = summarize_text(text)
                keywords = extract_keywords(text)
                results.append({
                    "title": article["title"],
                    "link": article["link"],
                    "summary": summary,
                    "keywords": ", ".join(keywords),
                    "collected_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })
            
            # ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€
            if results:
                new_df = pd.DataFrame(results)
                try:
                    existing_df = pd.read_csv('yna_digital_healthcare_news.csv')
                    combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                except FileNotFoundError:
                    combined_df = new_df
                
                combined_df.to_csv('yna_digital_healthcare_news.csv', index=False, encoding='utf-8-sig')
                
        except Exception as e:
            print(f"ìë™ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
    
    # ê¸°ì¡´ ìŠ¤ì¼€ì¤„ ëª¨ë‘ ì‚­ì œ
    schedule.clear()
    
    # ë§¤ì¼ ì˜¤ì „ 9ì‹œì— ì‹¤í–‰
    schedule.every().day.at("09:00").do(collect_daily_news)
    
    def run_scheduler():
        while st.session_state.scheduler_running:
            schedule.run_pending()
            time.sleep(60)
    
    # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ ìƒˆ ìŠ¤ë ˆë“œ ì‹œì‘
    if not st.session_state.scheduler_running:
        st.session_state.scheduler_running = True
        scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
        scheduler_thread.start()
        st.session_state.scheduler_thread = scheduler_thread
        return "ìë™ ìŠ¤ì¼€ì¤„ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. (ë§¤ì¼ ì˜¤ì „ 9ì‹œ)"
    else:
        return "ìë™ ìŠ¤ì¼€ì¤„ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."

# ìŠ¤ì¼€ì¤„ë§ ì¤‘ì§€ í•¨ìˆ˜
def stop_scheduler():
    st.session_state.scheduler_running = False
    schedule.clear()
    return "ìë™ ìŠ¤ì¼€ì¤„ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."

# ê¸°ì¡´ ë°ì´í„° í‘œì‹œ
st.subheader("ğŸ“Š ê¸°ì¡´ ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ ë‰´ìŠ¤ ë°ì´í„°")
existing_df = load_existing_data()

if not existing_df.empty:
    # ê²€ìƒ‰ í•„í„° ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.subheader("ğŸ” ê²€ìƒ‰ í•„í„°")
        
        # í‚¤ì›Œë“œ í•„í„°
        keyword_filter = st.text_input("í‚¤ì›Œë“œ ê²€ìƒ‰", placeholder="ì œëª©, ìš”ì•½, í‚¤ì›Œë“œì—ì„œ ê²€ìƒ‰...")
        
        # ìš”ì•½ ê¸¸ì´ í•„í„°
        st.write("ìš”ì•½ ê¸¸ì´ ë²”ìœ„")
        summary_length_range = st.slider(
            "ë¬¸ì ìˆ˜",
            min_value=0,
            max_value=500,
            value=(0, 500),
            step=10
        )
        
        # í•„í„° ì ìš© ë²„íŠ¼
        if st.button("ğŸ” í•„í„° ì ìš©"):
            st.session_state.apply_filter = True
        
        # í•„í„° ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ í•„í„° ì´ˆê¸°í™”"):
            st.session_state.apply_filter = False
            st.rerun()
    
    # í•„í„° ì ìš©
    if hasattr(st.session_state, 'apply_filter') and st.session_state.apply_filter:
        filtered_df = filter_data(
            existing_df, 
            keyword_filter=keyword_filter,
            summary_length_filter=summary_length_range if summary_length_range != (0, 500) else None
        )
        st.info(f"í•„í„° ì ìš© ê²°ê³¼: {len(filtered_df)}ê°œ ê¸°ì‚¬ (ì „ì²´ {len(existing_df)}ê°œ ì¤‘)")
        display_df = filtered_df
    else:
        display_df = existing_df
    
    # íƒ­ìœ¼ë¡œ êµ¬ì„±
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ ë°ì´í„° í…Œì´ë¸”", "â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ", "ğŸ“ˆ ìš”ì•½ ë¹„êµ", "ğŸ“§ ì´ë©”ì¼ ì „ì†¡"])
    
    with tab1:
        # í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ë¡œ ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
        try:
            df_with_links = make_clickable_links(display_df)
            st.markdown(df_with_links.to_html(escape=False, index=False), unsafe_allow_html=True)
        except Exception as e:
            st.error(f"ë§í¬ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.dataframe(display_df)
        
        # ê¸°ì¡´ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ
        csv_existing = existing_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ê¸°ì¡´ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_existing,
            file_name=f"ë””ì§€í„¸í—¬ìŠ¤ì¼€ì–´_ë‰´ìŠ¤ë°ì´í„°_{time.strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    with tab2:
        st.subheader("â˜ï¸ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
        
        # í°íŠ¸ ìƒíƒœ í™•ì¸ ë²„íŠ¼
        col1, col2 = st.columns([3, 1])
        with col2:
            if st.button("ğŸ” í°íŠ¸ ìƒíƒœ í™•ì¸"):
                font_path = get_korean_font_path()
                if font_path:
                    st.success(f"âœ… í•œê¸€ í°íŠ¸ ë°œê²¬: {os.path.basename(font_path)}")
                else:
                    st.error("âŒ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        if 'keywords' in existing_df.columns:
            # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì§„í–‰ ìƒí™© í‘œì‹œ
            with st.spinner("ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘..."):
                wordcloud = create_wordcloud(existing_df['keywords'])
            
            if wordcloud:
                # matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •
                plt.rcParams['font.family'] = ['Malgun Gothic', 'DejaVu Sans']
                plt.rcParams['axes.unicode_minus'] = False
                
                # ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ
                fig, ax = plt.subplots(figsize=(12, 6))
                ax.imshow(wordcloud, interpolation='bilinear')
                ax.axis('off')
                ax.set_title('í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ', fontsize=16, pad=20)
                
                # ê³ í•´ìƒë„ë¡œ í‘œì‹œ
                st.pyplot(fig, dpi=150)
                plt.close(fig)  # ë©”ëª¨ë¦¬ ì •ë¦¬
                
                # í‚¤ì›Œë“œ ë¹ˆë„ ì°¨íŠ¸
                st.subheader("ğŸ“Š í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„")
                all_keywords = []
                for keywords_str in existing_df['keywords']:
                    if pd.notna(keywords_str):
                        keywords = [k.strip() for k in str(keywords_str).split(',')]
                        keywords = [k for k in keywords if k and len(k) > 1]  # ë¹ˆ í‚¤ì›Œë“œ ì œê±°
                        all_keywords.extend(keywords)
                
                if all_keywords:
                    keyword_freq = Counter(all_keywords)
                    top_keywords = dict(keyword_freq.most_common(15))  # ìƒìœ„ 15ê°œë¡œ ì¦ê°€
                    
                    # í•œê¸€ í‚¤ì›Œë“œë§Œ í•„í„°ë§
                    korean_keywords = {}
                    for k, v in top_keywords.items():
                        if any('\uac00' <= char <= '\ud7a3' for char in k):  # í•œê¸€ í¬í•¨ í™•ì¸
                            korean_keywords[k] = v
                    
                    if korean_keywords:
                        fig_bar = px.bar(
                            x=list(korean_keywords.values()),
                            y=list(korean_keywords.keys()),
                            orientation='h',
                            title="ìƒìœ„ í‚¤ì›Œë“œ ë¹ˆë„ (í•œê¸€)",
                            labels={'x': 'ë¹ˆë„', 'y': 'í‚¤ì›Œë“œ'},
                            color=list(korean_keywords.values()),
                            color_continuous_scale='viridis'
                        )
                        fig_bar.update_layout(
                            height=500,
                            font=dict(size=12),
                            title_font_size=16
                        )
                        st.plotly_chart(fig_bar, use_container_width=True)
                        
                        # í‚¤ì›Œë“œ í†µê³„ ì •ë³´
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì´ í‚¤ì›Œë“œ ìˆ˜", len(all_keywords))
                        with col2:
                            st.metric("ê³ ìœ  í‚¤ì›Œë“œ ìˆ˜", len(keyword_freq))
                        with col3:
                            st.metric("í‰ê·  ë¹ˆë„", f"{sum(keyword_freq.values()) / len(keyword_freq):.1f}")
                    else:
                        st.warning("í•œê¸€ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.error("ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
                # ëŒ€ì•ˆ ì œì‹œ
                st.info("ğŸ’¡ í•´ê²° ë°©ë²•:")
                st.markdown("""
                1. **í•œê¸€ í°íŠ¸ ì„¤ì¹˜ í™•ì¸**: Windows ì„¤ì • > ì‹œê°„ ë° ì–¸ì–´ > ì–¸ì–´ì—ì„œ í•œêµ­ì–´ ì–¸ì–´íŒ© ì„¤ì¹˜
                2. **í°íŠ¸ íŒŒì¼ í™•ì¸**: C:/Windows/Fonts/ í´ë”ì— malgun.ttf íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                3. **ê¶Œí•œ ë¬¸ì œ**: ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰ ì‹œë„
                """)
        else:
            st.warning("í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with tab3:
        st.subheader("ğŸ“ˆ ìš”ì•½ ë°©ë²• ë¹„êµ")
        if 'summary' in existing_df.columns and len(existing_df) > 0:
            # ì²« ë²ˆì§¸ ê¸°ì‚¬ë¡œ ìš”ì•½ ë¹„êµ ë°ëª¨
            selected_idx = st.selectbox("ë¹„êµí•  ê¸°ì‚¬ ì„ íƒ", range(len(existing_df)), 
                                      format_func=lambda x: existing_df.iloc[x]['title'][:50] + "...")
            
            if st.button("ìš”ì•½ ë¹„êµ ì‹¤í–‰"):
                selected_article = existing_df.iloc[selected_idx]
                
                # ë” ê¸´ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ìƒì„± (ì‹¤ì œ ë‰´ìŠ¤ ê¸°ì‚¬ì²˜ëŸ¼)
                extended_text = f"""
                {selected_article['title']}
                
                {selected_article.get('summary', '')}
                
                ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ ë¶„ì•¼ëŠ” ìµœê·¼ ëª‡ ë…„ê°„ ê¸‰ì†í•œ ë°œì „ì„ ë³´ì´ê³  ìˆë‹¤. 
                ì¸ê³µì§€ëŠ¥, ë¹…ë°ì´í„°, IoT ë“±ì˜ ê¸°ìˆ ì´ ì˜ë£Œ ì„œë¹„ìŠ¤ì™€ ê²°í•©ë˜ë©´ì„œ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ë§Œë“¤ì–´ê°€ê³  ìˆë‹¤.
                
                ì „ë¬¸ê°€ë“¤ì€ ì´ëŸ¬í•œ ë³€í™”ê°€ ì˜ë£Œ ì ‘ê·¼ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ê²ƒìœ¼ë¡œ ì „ë§í•œë‹¤ê³  ë°í˜”ë‹¤.
                íŠ¹íˆ ì›ê²© ì§„ë£Œ ì„œë¹„ìŠ¤ì˜ í™•ì‚°ìœ¼ë¡œ ì§€ì—­ ê°„ ì˜ë£Œ ê²©ì°¨ í•´ì†Œì—ë„ ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤.
                
                ê·¸ëŸ¬ë‚˜ ê°œì¸ì •ë³´ ë³´í˜¸ì™€ ì˜ë£Œ ë°ì´í„° ë³´ì•ˆì— ëŒ€í•œ ìš°ë ¤ë„ í•¨ê»˜ ì œê¸°ë˜ê³  ìˆì–´, 
                ê´€ë ¨ ë²•ê·œ ì •ë¹„ì™€ ê¸°ìˆ ì  ë³´ì™„ì´ í•„ìš”í•œ ìƒí™©ì´ë‹¤.
                
                ì—…ê³„ ê´€ê³„ìëŠ” "ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ ê¸°ìˆ ì˜ ë°œì „ê³¼ í•¨ê»˜ í™˜ì ì¤‘ì‹¬ì˜ ì˜ë£Œ ì„œë¹„ìŠ¤ê°€ 
                ë”ìš± ë°œì „í•  ê²ƒ"ì´ë¼ë©° "ì§€ì†ì ì¸ íˆ¬ìì™€ ì—°êµ¬ê°œë°œì´ ì¤‘ìš”í•˜ë‹¤"ê³  ê°•ì¡°í–ˆë‹¤.
                """.strip()
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ğŸ”¤ TextRank ìš”ì•½")
                    textrank_result = textrank_summarize(extended_text)
                    
                    # TextRank ê²°ê³¼ë¥¼ ë°•ìŠ¤ í˜•íƒœë¡œ í‘œì‹œ
                    st.markdown(f"""
                    <div style="background-color: #f0f2f6; padding: 15px; border-radius: 10px; border-left: 4px solid #1f77b4;">
                        {textrank_result}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    st.info(f"ê¸¸ì´: {len(textrank_result)} ë¬¸ì")
                    
                    # TextRank íŠ¹ì§• ì„¤ëª…
                    st.caption("ğŸ“ TextRankëŠ” ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ìš”í•œ ë¬¸ì¥ì„ ì„ íƒí•©ë‹ˆë‹¤.")
                
                with col2:
                    st.subheader("ğŸ¤– KoBART ìŠ¤íƒ€ì¼ ìš”ì•½")
                    kobart_result = kobart_style_summarize(extended_text)
                    
                    # KoBART ê²°ê³¼ë¥¼ ë°•ìŠ¤ í˜•íƒœë¡œ í‘œì‹œ
                    st.markdown(f"""
                    <div style="background-color: #fff2e6; padding: 15px; border-radius: 10px; border-left: 4px solid #ff7f0e;">
                        {kobart_result}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    st.info(f"ê¸¸ì´: {len(kobart_result)} ë¬¸ì")
                    
                    # KoBART íŠ¹ì§• ì„¤ëª…
                    st.caption("ğŸ“ KoBART ìŠ¤íƒ€ì¼ì€ í‚¤ì›Œë“œì™€ ìœ„ì¹˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
                
                # ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´
                original_length = len(extended_text)
                
                # ìš”ì•½ í’ˆì§ˆ ë¹„êµ ì°¨íŠ¸
                comparison_data = {
                    'ìš”ì•½ ë°©ë²•': ['TextRank', 'KoBART ìŠ¤íƒ€ì¼'],
                    'ë¬¸ì ìˆ˜': [len(textrank_result), len(kobart_result)],
                    'ì••ì¶•ë¥ ': [len(textrank_result)/original_length*100, len(kobart_result)/original_length*100]
                }
                
                # ìƒì„¸ ë¹„êµ ì •ë³´
                st.subheader("ğŸ“Š ìƒì„¸ ë¹„êµ ë¶„ì„")
                
                col3, col4, col5 = st.columns(3)
                with col3:
                    st.metric("ì›ë³¸ í…ìŠ¤íŠ¸", f"{original_length} ë¬¸ì")
                with col4:
                    st.metric("TextRank ì••ì¶•ë¥ ", f"{comparison_data['ì••ì¶•ë¥ '][0]:.1f}%")
                with col5:
                    st.metric("KoBART ì••ì¶•ë¥ ", f"{comparison_data['ì••ì¶•ë¥ '][1]:.1f}%")
                
                # ì••ì¶•ë¥  ë¹„êµ ì°¨íŠ¸
                fig_comparison = px.bar(
                    comparison_data, 
                    x='ìš”ì•½ ë°©ë²•', 
                    y='ì••ì¶•ë¥ ',
                    title="ìš”ì•½ ë°©ë²•ë³„ ì••ì¶•ë¥  ë¹„êµ (%)",
                    color='ìš”ì•½ ë°©ë²•',
                    color_discrete_map={
                        'TextRank': '#1f77b4',
                        'KoBART ìŠ¤íƒ€ì¼': '#ff7f0e'
                    }
                )
                fig_comparison.update_layout(height=400)
                st.plotly_chart(fig_comparison, use_container_width=True)
                
                # ë¬¸ì¥ ìˆ˜ ë¹„êµ
                textrank_sentences = len(re.split(r'[.!?]\s+', textrank_result))
                kobart_sentences = len(re.split(r'[.!?]\s+', kobart_result))
                original_sentences = len(re.split(r'[.!?]\s+', extended_text))
                
                sentence_data = {
                    'êµ¬ë¶„': ['ì›ë³¸', 'TextRank', 'KoBART ìŠ¤íƒ€ì¼'],
                    'ë¬¸ì¥ ìˆ˜': [original_sentences, textrank_sentences, kobart_sentences]
                }
                
                fig_sentences = px.bar(
                    sentence_data,
                    x='êµ¬ë¶„',
                    y='ë¬¸ì¥ ìˆ˜',
                    title="ë¬¸ì¥ ìˆ˜ ë¹„êµ",
                    color='êµ¬ë¶„'
                )
                fig_sentences.update_layout(height=300)
                st.plotly_chart(fig_sentences, use_container_width=True)
        else:
            st.warning("ìš”ì•½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with tab4:
        st.subheader("ğŸ“§ ì´ë©”ì¼ ìë™ ì „ì†¡")
        
        # ì´ë©”ì¼ ì„¤ì • ì„¹ì…˜
        with st.expander("âš™ï¸ ì´ë©”ì¼ ì„¤ì •", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                sender_email = st.text_input(
                    "ë°œì‹ ì ì´ë©”ì¼ (Gmail)", 
                    placeholder="your_email@gmail.com",
                    help="Gmail ê³„ì •ì„ ì…ë ¥í•˜ì„¸ìš”"
                )
                sender_password = st.text_input(
                    "ì•± ë¹„ë°€ë²ˆí˜¸", 
                    type="password",
                    help="Gmail 2ë‹¨ê³„ ì¸ì¦ í›„ ìƒì„±í•œ ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
                )
            
            with col2:
                recipient_email = st.text_input(
                    "ìˆ˜ì‹ ì ì´ë©”ì¼", 
                    placeholder="recipient@example.com"
                )
                email_subject = st.text_input(
                    "ì´ë©”ì¼ ì œëª©",
                    value=f"ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ ë‰´ìŠ¤ ë¶„ì„ ë³´ê³ ì„œ - {datetime.now().strftime('%Y.%m.%d')}"
                )
        
        # ì „ì†¡í•  ë°ì´í„° ì„ íƒ
        st.subheader("ğŸ“‹ ì „ì†¡í•  ë°ì´í„° ì„ íƒ")
        
        # í˜„ì¬ í‘œì‹œëœ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
        use_filtered_data = st.checkbox(
            "í˜„ì¬ í•„í„°ë§ëœ ë°ì´í„° ì‚¬ìš©", 
            value=True,
            help="ì²´í¬í•˜ë©´ í˜„ì¬ í™”ë©´ì— í‘œì‹œëœ í•„í„°ë§ëœ ë°ì´í„°ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤"
        )
        
        if use_filtered_data:
            email_df = display_df
            st.info(f"ì „ì†¡í•  ë°ì´í„°: {len(email_df)}ê°œ ê¸°ì‚¬")
        else:
            email_df = existing_df
            st.info(f"ì „ì†¡í•  ë°ì´í„°: {len(email_df)}ê°œ ê¸°ì‚¬ (ì „ì²´ ë°ì´í„°)")
        
        # ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°
        if st.button("ğŸ“‹ ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°"):
            if not email_df.empty:
                st.subheader("ğŸ“§ ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°")
                
                # ë¯¸ë¦¬ë³´ê¸° HTML ìƒì„±
                preview_html = f"""
                <div style="border: 1px solid #ddd; padding: 20px; border-radius: 10px; background-color: #f9f9f9;">
                    <h2 style="color: #2E86AB;">ğŸ“° ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ ë‰´ìŠ¤ ë¶„ì„ ë³´ê³ ì„œ</h2>
                    <p><strong>ìƒì„± ì¼ì‹œ:</strong> {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}</p>
                    <p><strong>ì´ ê¸°ì‚¬ ìˆ˜:</strong> {len(email_df)}ê°œ</p>
                    
                    <h3>ğŸ“Š ë¶„ì„ ê²°ê³¼ (ìƒìœ„ 3ê°œ ê¸°ì‚¬)</h3>
                    {email_df.head(3).to_html(escape=False, index=False)}
                    
                    <div style="background-color: #f0f0f0; padding: 10px; margin: 10px 0; border-radius: 5px;">
                        <h3>ğŸ“ˆ ìš”ì•½ í†µê³„</h3>
                        <ul>
                            <li>í‰ê·  ìš”ì•½ ê¸¸ì´: {email_df['summary'].str.len().mean():.0f}ì</li>
                            <li>ì´ í‚¤ì›Œë“œ ìˆ˜: {sum(len(str(keywords).split(', ')) for keywords in email_df['keywords'] if pd.notna(keywords))}ê°œ</li>
                        </ul>
                    </div>
                </div>
                """
                
                st.markdown(preview_html, unsafe_allow_html=True)
            else:
                st.warning("ì „ì†¡í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì´ë©”ì¼ ì „ì†¡ ë²„íŠ¼
        st.divider()
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸ“¤ ì´ë©”ì¼ ì „ì†¡", type="primary", use_container_width=True):
                # ì…ë ¥ ê²€ì¦
                if not sender_email or not sender_password or not recipient_email:
                    st.error("ëª¨ë“  ì´ë©”ì¼ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                elif email_df.empty:
                    st.error("ì „ì†¡í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    with st.spinner("ì´ë©”ì¼ ì „ì†¡ ì¤‘..."):
                        success, message = send_email_report(
                            recipient_email=recipient_email,
                            subject=email_subject,
                            df=email_df,
                            sender_email=sender_email,
                            sender_password=sender_password
                        )
                    
                    if success:
                        st.success(message)
                        st.balloons()
                    else:
                        st.error(message)
                        
                        # ì¼ë°˜ì ì¸ ì˜¤ë¥˜ í•´ê²° ë°©ë²• ì•ˆë‚´
                        with st.expander("â“ ì´ë©”ì¼ ì „ì†¡ ì˜¤ë¥˜ í•´ê²° ë°©ë²•"):
                            st.markdown("""
                            **ì¼ë°˜ì ì¸ ì˜¤ë¥˜ í•´ê²° ë°©ë²•:**
                            
                            1. **Gmail 2ë‹¨ê³„ ì¸ì¦ ì„¤ì •**
                               - Gmail ê³„ì •ì—ì„œ 2ë‹¨ê³„ ì¸ì¦ì„ í™œì„±í™”í•˜ì„¸ìš”
                            
                            2. **ì•± ë¹„ë°€ë²ˆí˜¸ ìƒì„±**
                               - Google ê³„ì • ì„¤ì • â†’ ë³´ì•ˆ â†’ ì•± ë¹„ë°€ë²ˆí˜¸ì—ì„œ ìƒì„±
                               - ì¼ë°˜ Gmail ë¹„ë°€ë²ˆí˜¸ê°€ ì•„ë‹Œ ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
                            
                            3. **ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸**
                               - ì¸í„°ë„· ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”
                            
                            4. **ì´ë©”ì¼ ì£¼ì†Œ í™•ì¸**
                               - ë°œì‹ ìì™€ ìˆ˜ì‹ ì ì´ë©”ì¼ ì£¼ì†Œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”
                            """)
        
        # ìë™ ì „ì†¡ ì„¤ì •
        st.divider()
        st.subheader("â° ìë™ ì´ë©”ì¼ ì „ì†¡ ì„¤ì •")
        
        auto_email_enabled = st.checkbox("ìë™ ì´ë©”ì¼ ì „ì†¡ í™œì„±í™”")
        
        if auto_email_enabled:
            col1, col2 = st.columns(2)
            
            with col1:
                auto_email_time = st.time_input("ì „ì†¡ ì‹œê°„", value=datetime.now().time())
                auto_email_frequency = st.selectbox(
                    "ì „ì†¡ ì£¼ê¸°",
                    ["ë§¤ì¼", "ë§¤ì£¼", "ë§¤ì›”"],
                    index=0
                )
            
            with col2:
                auto_recipient = st.text_input("ìë™ ì „ì†¡ ìˆ˜ì‹ ì", value=recipient_email)
                
            if st.button("âš™ï¸ ìë™ ì „ì†¡ ì„¤ì • ì €ì¥"):
                st.success("ìë™ ì´ë©”ì¼ ì „ì†¡ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.info(f"ì„¤ì •: {auto_email_frequency} {auto_email_time.strftime('%H:%M')}ì— {auto_recipient}ë¡œ ì „ì†¡")
            
else:
    st.info("ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ìë™ ìŠ¤ì¼€ì¤„ë§ ì„¹ì…˜
st.divider()
st.subheader("â° ìë™ ìŠ¤ì¼€ì¤„ë§")

# í˜„ì¬ ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í‘œì‹œ
if st.session_state.scheduler_running:
    st.success("ğŸŸ¢ ìë™ ìŠ¤ì¼€ì¤„ë§ì´ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤ (ë§¤ì¼ ì˜¤ì „ 9ì‹œ)")
else:
    st.info("ğŸ”´ ìë™ ìŠ¤ì¼€ì¤„ë§ì´ ì¤‘ì§€ë˜ì–´ ìˆìŠµë‹ˆë‹¤")

col1, col2, col3 = st.columns(3)

with col1:
    if st.button("ğŸš€ ìŠ¤ì¼€ì¤„ë§ ì‹œì‘", disabled=st.session_state.scheduler_running):
        try:
            message = schedule_daily_news_collection()
            st.success(message)
            st.rerun()
        except Exception as e:
            st.error(f"ìŠ¤ì¼€ì¤„ë§ ì‹œì‘ ì‹¤íŒ¨: {e}")

with col2:
    if st.button("â¹ï¸ ìŠ¤ì¼€ì¤„ë§ ì¤‘ì§€", disabled=not st.session_state.scheduler_running):
        try:
            message = stop_scheduler()
            st.success(message)
            st.rerun()
        except Exception as e:
            st.error(f"ìŠ¤ì¼€ì¤„ë§ ì¤‘ì§€ ì‹¤íŒ¨: {e}")

with col3:
    if st.button("ğŸ“… ìƒíƒœ í™•ì¸"):
        jobs = schedule.jobs
        if jobs:
            st.write("**í™œì„± ìŠ¤ì¼€ì¤„:**")
            for i, job in enumerate(jobs, 1):
                st.write(f"{i}. ë§¤ì¼ 09:00 - ë‰´ìŠ¤ ìˆ˜ì§‘")
        else:
            st.write("í™œì„±í™”ëœ ìŠ¤ì¼€ì¤„ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ìŠ¤ë ˆë“œ ìƒíƒœë„ í‘œì‹œ
        if st.session_state.scheduler_running:
            st.write("**ìŠ¤ì¼€ì¤„ëŸ¬ ìŠ¤ë ˆë“œ:** ì‹¤í–‰ ì¤‘")
        else:
            st.write("**ìŠ¤ì¼€ì¤„ëŸ¬ ìŠ¤ë ˆë“œ:** ì¤‘ì§€ë¨")

st.divider()

# ìƒˆë¡œìš´ ê²€ìƒ‰ UI
st.subheader("ğŸ” ìƒˆë¡œìš´ ë‰´ìŠ¤ ê²€ìƒ‰ ë° ë¶„ì„")
with st.form("news_form"):
    keyword = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ", value="ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´")
    num_articles = st.slider("ê¸°ì‚¬ ê°œìˆ˜", min_value=1, max_value=10, value=5)
    submitted = st.form_submit_button("ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„")

if submitted:
    try:
        with st.spinner("ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘ ì¤‘..."):
            articles = get_yna_article_links(keyword, pages=1)[:num_articles]
        
        if not articles:
            st.warning("ê²€ìƒ‰ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
        else:
            st.info(f"ì´ {len(articles)}ê°œì˜ ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            results = []
            for i, article in enumerate(articles):
                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                progress = (i + 1) / len(articles)
                progress_bar.progress(progress)
                status_text.text(f"ë¶„ì„ ì¤‘... ({i + 1}/{len(articles)}) {article['title'][:50]}...")
                
                try:
                    text = extract_yna_article_text(article["link"])
                    summary = summarize_text(text) if text else "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    keywords = extract_keywords(text) if text else []
                    
                    results.append({
                        "ì œëª©": article["title"],
                        "ë§í¬": article["link"],
                        "ìš”ì•½": summary,
                        "í‚¤ì›Œë“œ": ", ".join(keywords) if keywords else "í‚¤ì›Œë“œ ì—†ìŒ"
                    })
                except Exception as e:
                    st.warning(f"ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {article['title'][:30]}... - {str(e)}")
                    results.append({
                        "ì œëª©": article["title"],
                        "ë§í¬": article["link"],
                        "ìš”ì•½": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                        "í‚¤ì›Œë“œ": "ì˜¤ë¥˜"
                    })
            
            # ì§„í–‰ ìƒí™© ì™„ë£Œ
            progress_bar.progress(1.0)
            status_text.text("ë¶„ì„ ì™„ë£Œ!")
            st.success("âœ… ë‰´ìŠ¤ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ê²°ê³¼ í‘œì‹œ
            if results:
                st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
                df = pd.DataFrame(results)
                
                # ë§í¬ë¥¼ í•˜ì´í¼ë§í¬ë¡œ ë³€í™˜í•œ ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
                df_with_links = make_clickable_links(df)
                st.markdown(df_with_links.to_html(escape=False, index=False), unsafe_allow_html=True)
                
                # í†µê³„ ì •ë³´
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì´ ê¸°ì‚¬ ìˆ˜", len(results))
                with col2:
                    avg_summary_length = sum(len(r["ìš”ì•½"]) for r in results) / len(results)
                    st.metric("í‰ê·  ìš”ì•½ ê¸¸ì´", f"{avg_summary_length:.0f}ì")
                with col3:
                    total_keywords = sum(len(r["í‚¤ì›Œë“œ"].split(", ")) for r in results if r["í‚¤ì›Œë“œ"] != "í‚¤ì›Œë“œ ì—†ìŒ")
                    st.metric("ì´ í‚¤ì›Œë“œ ìˆ˜", total_keywords)
                
                # CSV ë‹¤ìš´ë¡œë“œ
                csv = df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name=f"{keyword}_ë‰´ìŠ¤ë¶„ì„_{time.strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
            else:
                st.warning("ë¶„ì„í•  ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
    except Exception as e:
        st.error(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.info("ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")